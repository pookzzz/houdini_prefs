{"type": "root", "attrs": {"type": "node", "context": "sop", "internal": "labs::av_analyze_images::5.0", "icon": "alicevision.png", "tags": "sidefxlabs,  photogrammetry", "version": "5.0", "namespace": "labs"}, "body": [{"level": 0, "type": "title", "indent": 0, "text": ["Labs AV Analyze Images"], "extent": [0, 27]}, {"type": "summary", "indent": 0, "text": [" Match all features between candidate image pairs using Alicevision. "], "extent": [153, 230]}, {"type": "para", "indent": 0, "text": ["The objective of this step is to extract distinctive groups of pixels that are, to some extent, invariant to changing camera viewpoints during image acquisition, and to match all features between candidate image pairs."], "extent": [230, 450]}, {"type": "warning_group", "body": [{"type": "warning", "indent": 0, "role": "item", "extent": [450, 459], "body": [{"type": "para", "indent": 4, "text": ["Requires Meshroom/AliceVision version 2021.1.0."], "extent": [459, 512]}], "container": true}], "container": true, "role": "item_group"}, {"level": 1, "id": "parameters", "container": true, "type": "parameters_section", "indent": 0, "role": "section", "extent": [512, 524], "body": [{"level": 2, "id": null, "container": true, "type": "h", "indent": 4, "text": ["Main"], "extent": [524, 539], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 4, "text": ["Cook"], "extent": [539, 549], "body": [{"type": "para", "indent": 8, "text": ["Start the cooking process for this step."], "extent": [549, 598]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Manual Mode"], "extent": [598, 615], "body": [{"type": "para", "indent": 8, "text": ["This toggle controls if the node should automatically recook if any dependencies have changed."], "extent": [615, 718]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Use Log"], "extent": [718, 731], "body": [{"type": "para", "indent": 8, "text": ["This toggle controls if the status of the current node should be printed to the console. This is useful for getting a quick overview of the progress."], "extent": [731, 889]}], "container": true, "role": "item"}], "container": true, "role": "item_group"}]}, {"level": 2, "id": null, "container": true, "type": "h", "indent": 4, "text": ["Feature Extraction"], "extent": [889, 918], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 4, "text": ["Describer Types"], "extent": [918, 939], "body": [{"type": "para", "indent": 8, "text": ["Describer types used to describe an image."], "extent": [939, 990]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Describer Preset"], "extent": [990, 1012], "body": [{"type": "para", "indent": 8, "text": ["Control the ImageDescriber configuration (low, medium, normal, high, ultra). Configuration ", {"type": "q", "text": ["ultra"]}, " can take long time !"], "extent": [1012, 1140]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Force CPU Extraction"], "extent": [1140, 1166], "body": [{"type": "para", "indent": 8, "text": ["Use only CPU feature extraction."], "extent": [1166, 1207]}], "container": true, "role": "item"}], "container": true, "role": "item_group"}]}, {"level": 2, "id": null, "container": true, "type": "h", "indent": 4, "text": ["Image Matching"], "extent": [1207, 1232], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 4, "text": ["Min Number of Images"], "extent": [1232, 1258], "body": [{"type": "para", "indent": 8, "text": ["Minimal number of images to use the vocabulary tree. If we have less features than this threshold, we will compute all matching combinations."], "extent": [1258, 1408]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Max Descriptors"], "extent": [1408, 1429], "body": [{"type": "para", "indent": 8, "text": ["Limit the number of descriptors you load per image. Zero means no limit."], "extent": [1429, 1510]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Number of Matches"], "extent": [1510, 1533], "body": [{"type": "para", "indent": 8, "text": ["The number of matches to retrieve for each image (If 0 it will retrieve all the matches)."], "extent": [1533, 1631]}], "container": true, "role": "item"}], "container": true, "role": "item_group"}]}, {"level": 2, "id": null, "container": true, "type": "h", "indent": 4, "text": ["Feature Matching"], "extent": [1631, 1658], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 4, "text": ["Describer Types"], "extent": [1658, 1679], "body": [{"type": "para", "indent": 8, "text": ["Describer types used to describe an image."], "extent": [1679, 1730]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Photometric Matching Method"], "extent": [1730, 1763], "body": [{"type": "para", "indent": 8, "text": ["For Scalar based regions descriptor \u2013\n        ' BRUTE_FORCE_L2: L2 BruteForce matching'"], "extent": [1763, 1861]}, {"type": "para", "indent": 8, "text": ["' ANN_L2: L2 Approximate Nearest Neighbor matching'"], "extent": [1861, 1922]}, {"type": "para", "indent": 8, "text": ["' CASCADE_HASHING_L2: L2 Cascade Hashing matching'"], "extent": [1922, 1982]}, {"type": "para", "indent": 8, "text": ["' FAST_CASCADE_HASHING_L2: L2 Cascade Hashing with precomputed hashed regions (faster than CASCADE_HASHING_L2 but use more memory)"], "extent": [1982, 2123]}, {"type": "para", "indent": 8, "text": ["For Binary based descriptor \u2013 \n        ' BRUTE_FORCE_HAMMING: BruteForce Hamming matching'"], "extent": [2123, 2223]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Geometric Error"], "extent": [2223, 2244], "body": [{"type": "para", "indent": 8, "text": ["Maximum error allowed for features matching during geometric verification."], "extent": [2244, 2327]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Geometric Filter type"], "extent": [2327, 2354], "body": [{"type": "para", "indent": 8, "text": ["Geometric validation method to filter features matches."], "extent": [2354, 2418]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Distance Ratio"], "extent": [2418, 2438], "body": [{"type": "para", "indent": 8, "text": ["Distance ratio to discard non meaningful matches."], "extent": [2438, 2496]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Max Iteration"], "extent": [2496, 2515], "body": [{"type": "para", "indent": 8, "text": ["Maximum number of iterations allowed in ransac step."], "extent": [2515, 2576]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Max Matches"], "extent": [2576, 2593], "body": [{"type": "para", "indent": 8, "text": ["Maximum number of matches to keep."], "extent": [2593, 2636]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Save Putative Matches"], "extent": [2636, 2663], "body": [{"type": "para", "indent": 8, "text": ["Putative matches."], "extent": [2663, 2689]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Guided Matches"], "extent": [2689, 2709], "body": [{"type": "para", "indent": 8, "text": ["The found model to improve the pairwise correspondences."], "extent": [2709, 2774]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Export Debug Files"], "extent": [2774, 2798], "body": [{"type": "para", "indent": 8, "text": ["Debug files (svg, dot)."], "extent": [2798, 2831]}], "container": true, "role": "item"}], "container": true, "role": "item_group"}]}, {"level": 2, "id": null, "container": true, "type": "h", "indent": 4, "text": ["Environment"], "extent": [2831, 2853], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 4, "text": ["Environment"], "extent": [2853, 2870], "body": [{"type": "para", "indent": 8, "text": ["The environment used for launching the AliceVision utilities command line. Note that this is a python expression and should be modified only through ", {"type": "q", "text": ["Edit Expression"]}, "."], "extent": [2870, 3048]}], "container": true, "role": "item"}], "container": true, "role": "item_group"}]}], "text": "Parameters"}, {"level": 1, "id": "examples", "container": true, "type": "examples_section", "indent": 0, "role": "section", "extent": [3048, 3058], "body": [{"type": "bullet_group", "body": [{"blevel": 6, "type": "bullet", "indent": 4, "text": [{"scheme": null, "value": "https://github.com/sideeffects/SideFXLabs/blob/Development/hip/examples/alicevision", "type": "link", "text": ["Example File"], "exists": true}], "extent": [3058, 3164]}], "container": true}], "text": "Examples"}], "title": ["Labs AV Analyze Images"], "summary": [" Match all features between candidate image pairs using Alicevision. "]}