{"type": "root", "attrs": {"type": "node", "context": "sop", "internal": "labs::av_depth_map::5.0", "icon": "alicevision.png", "tags": "sidefxlabs,  photogrammetry", "version": "5.0", "namespace": "labs"}, "body": [{"level": 0, "type": "title", "indent": 0, "text": ["Labs AV Depth Map"], "extent": [0, 22]}, {"type": "summary", "indent": 0, "text": ["  Retrieves the depth value of each pixel from the cameras using Alicevision. "], "extent": [143, 229]}, {"type": "para", "indent": 0, "text": ["The objective of this step is to retrieve the depth value for each pixel in the images and cameras that had previously been resolved by Structure From Motion. This can take a very long time depending on the resolution and number of images provided."], "extent": [229, 479]}, {"type": "warning_group", "body": [{"type": "warning", "indent": 0, "role": "item", "extent": [479, 488], "body": [{"type": "para", "indent": 4, "text": ["Requires Meshroom/AliceVision version 2021.1.0."], "extent": [488, 541]}], "container": true}], "container": true, "role": "item_group"}, {"level": 1, "id": "parameters", "container": true, "type": "parameters_section", "indent": 0, "role": "section", "extent": [541, 553], "body": [{"level": 2, "id": null, "container": true, "type": "h", "indent": 4, "text": ["Main"], "extent": [553, 568], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 4, "text": ["Cook"], "extent": [568, 578], "body": [{"type": "para", "indent": 8, "text": ["Start the cooking process for this step."], "extent": [578, 627]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Manual Mode"], "extent": [627, 644], "body": [{"type": "para", "indent": 8, "text": ["This toggle controls if the node should automatically recook if any dependencies have changed."], "extent": [644, 747]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Use Log"], "extent": [747, 760], "body": [{"type": "para", "indent": 8, "text": ["This toggle controls if the status of the current node should be printed to the console. This is useful for getting a quick overview of the progress."], "extent": [760, 918]}], "container": true, "role": "item"}], "container": true, "role": "item_group"}]}, {"level": 2, "id": null, "container": true, "type": "h", "indent": 4, "text": ["Depth Map"], "extent": [918, 938], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 4, "text": ["Downscale"], "extent": [938, 953], "body": [{"type": "para", "indent": 8, "text": ["Image downscale factor."], "extent": [953, 985]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["SGM: Num Neighbor Cameras"], "extent": [985, 1016], "body": [{"type": "para", "indent": 8, "text": ["Semi Global Matching: Number of neighbour cameras."], "extent": [1016, 1075]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["SGM: WSH"], "extent": [1075, 1089], "body": [{"type": "para", "indent": 8, "text": ["Semi Global Matching: Half-size of the patch used to compute the similarity."], "extent": [1089, 1174]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["SGM: GammaC"], "extent": [1174, 1191], "body": [{"type": "para", "indent": 8, "text": ["Semi Global Matching: GammaC Threshold."], "extent": [1191, 1239]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["SGM: GammaP"], "extent": [1239, 1256], "body": [{"type": "para", "indent": 8, "text": ["Semi Global Matching: GammaP Threshold."], "extent": [1256, 1304]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Refine: Num of Samples"], "extent": [1304, 1332], "body": [{"type": "para", "indent": 8, "text": ["Refine: Number of samples."], "extent": [1332, 1367]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Refine: Num of Depths"], "extent": [1367, 1394], "body": [{"type": "para", "indent": 8, "text": ["Refine: Number of depths."], "extent": [1394, 1428]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Refine: Num of Iterations"], "extent": [1428, 1459], "body": [{"type": "para", "indent": 8, "text": ["Refine: Number of iterations."], "extent": [1459, 1497]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Refine: WSH"], "extent": [1497, 1514], "body": [{"type": "para", "indent": 8, "text": ["Refine: Half-size of the patch used to compute the similarity."], "extent": [1514, 1585]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Refine: Num Neighbor Cameras"], "extent": [1585, 1619], "body": [{"type": "para", "indent": 8, "text": ["Refine: Number of neighbour cameras."], "extent": [1619, 1664]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Refine: Sigma"], "extent": [1664, 1683], "body": [{"type": "para", "indent": 8, "text": ["Refine: Sigma Threshold."], "extent": [1683, 1716]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Refine: GammaC"], "extent": [1716, 1736], "body": [{"type": "para", "indent": 8, "text": ["Refine: GammaC Threshold."], "extent": [1736, 1770]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Refine: GammaP"], "extent": [1770, 1790], "body": [{"type": "para", "indent": 8, "text": ["Refine: GammaP threshold."], "extent": [1790, 1824]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Refine: Tc or Rc Pixel Size"], "extent": [1824, 1857], "body": [{"type": "para", "indent": 8, "text": ["Refine: Use minimum pixel size of neighbour cameras (Tc) or current camera pixel size (Rc)."], "extent": [1857, 1957]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Min View Angle"], "extent": [1957, 1977], "body": [{"type": "para", "indent": 8, "text": ["Minimum angle between two views."], "extent": [1977, 2018]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Max View Angle"], "extent": [2018, 2038], "body": [{"type": "para", "indent": 8, "text": ["Maximum angle between two views."], "extent": [2038, 2079]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Number of GPUs"], "extent": [2079, 2099], "body": [{"type": "para", "indent": 8, "text": ["Number of GPUs to use (0 means use all available GPUs)."], "extent": [2099, 2163]}], "container": true, "role": "item"}], "container": true, "role": "item_group"}]}, {"level": 2, "id": null, "container": true, "type": "h", "indent": 4, "text": ["Depth Map Filter"], "extent": [2163, 2190], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 4, "text": ["Number of Nearest Cameras"], "extent": [2190, 2221], "body": [{"type": "para", "indent": 8, "text": ["Number of nearest cameras used for filtering."], "extent": [2221, 2275]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Min Consistent Cameras"], "extent": [2275, 2303], "body": [{"type": "para", "indent": 8, "text": ["Min Number of Consistent Cameras."], "extent": [2303, 2345]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Min Consistent Cameras Bad Similarity"], "extent": [2345, 2388], "body": [{"type": "para", "indent": 8, "text": ["Min Number of Consistent Cameras for pixels with weak similarity value."], "extent": [2388, 2468]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Filtering Size in Pixels"], "extent": [2468, 2498], "body": [{"type": "para", "indent": 8, "text": ["Filtering size in pixels."], "extent": [2498, 2532]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Filtering Size in Pixels Bad Similarity"], "extent": [2532, 2577], "body": [{"type": "para", "indent": 8, "text": ["Filtering size in pixels."], "extent": [2577, 2611]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Min View Angle"], "extent": [2611, 2631], "body": [{"type": "para", "indent": 8, "text": ["Minimum angle between two views."], "extent": [2631, 2672]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Max View Angle"], "extent": [2672, 2692], "body": [{"type": "para", "indent": 8, "text": ["Maximum angle between two views."], "extent": [2692, 2733]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Compute normal maps per depth map"], "extent": [2733, 2772], "body": [{"type": "para", "indent": 8, "text": ["Compute normal maps per depth map."], "extent": [2772, 2816]}], "container": true, "role": "item"}], "container": true, "role": "item_group"}]}, {"level": 2, "id": null, "container": true, "type": "h", "indent": 4, "text": ["Environment"], "extent": [2816, 2838], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 4, "text": ["Environment"], "extent": [2838, 2855], "body": [{"type": "para", "indent": 8, "text": ["The environment used for launching the AliceVision utilities command line. Note that this is a python expression and should be modified only through ", {"type": "q", "text": ["Edit Expression"]}, "."], "extent": [2855, 3032]}], "container": true, "role": "item"}], "container": true, "role": "item_group"}]}], "text": "Parameters"}, {"level": 1, "id": "examples", "container": true, "type": "examples_section", "indent": 0, "role": "section", "extent": [3032, 3042], "body": [{"type": "bullet_group", "body": [{"blevel": 6, "type": "bullet", "indent": 4, "text": [{"scheme": null, "value": "https://github.com/sideeffects/SideFXLabs/blob/Development/hip/examples/alicevision", "type": "link", "text": ["Example File"], "exists": true}], "extent": [3042, 3147]}], "container": true}], "text": "Examples"}], "title": ["Labs AV Depth Map"], "summary": ["  Retrieves the depth value of each pixel from the cameras using Alicevision. "]}