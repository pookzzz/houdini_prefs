{"type": "root", "attrs": {"icon": "ROP/mantra", "context": "sop", "type": "node", "internal": "deep_to_points_ql", "version": "1", "namespace": "qLib"}, "body": [{"level": 0, "type": "title", "indent": 0, "text": ["Deep to Points qL"], "extent": [45, 67]}, {"type": "para", "indent": 0, "text": [{"type": "strong", "text": ["version 1"]}], "extent": [67, 81]}, {"type": "summary", "indent": 0, "text": ["Loads a deep raster image as a point cloud."], "extent": [81, 132]}, {"type": "para", "indent": 0, "text": ["This node loads a deep raster (DSM/DCM or deep EXR) image as a point cloud, where each point\nrepresents a sample of the deep image. Depth buffers (", {"type": "var", "text": ["Pz"]}, ") of regular images are also supported."], "extent": [132, 326]}, {"type": "para", "indent": 0, "text": [{"scheme": "Image", "value": "/nodes/sop/qLib--deep_to_points_ql-1/deep_to_points_ql_main.png", "type": "img", "text": ""}], "extent": [326, 369]}, {"type": "bullet_group", "body": [{"blevel": 2, "type": "bullet", "indent": 0, "text": [{"type": "em", "text": ["Deep point cloud with ", {"type": "var", "text": ["Of_avg"]}, " attribute visualised."]}], "extent": [369, 429]}], "container": true}, {"type": "warning_group", "body": [{"type": "warning", "indent": 0, "role": "item", "extent": [429, 438], "body": [{"type": "para", "indent": 4, "text": ["When loading a deep image ", {"type": "em", "text": ["sequence"]}, ", Houdini\u2019s texture memory cache might fill up fast\n    with the deep data. It\u2019s recommended to use a Cache SOP after this node to cache the\n    generated points, then flush the texture cache."], "extent": [438, 676]}, {"type": "para", "indent": 4, "text": ["(Currently the ", {"type": "q", "text": ["reload"]}, " button of the ", {"type": "em", "text": ["Deep Image"]}, " parameter will flush all texture caches.)"], "extent": [676, 775]}], "container": true}], "container": true, "role": "item_group"}, {"level": 1, "id": "parameters", "container": true, "type": "parameters_section", "indent": 0, "role": "section", "extent": [775, 787], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 4, "text": ["Deep Image"], "extent": [787, 803], "body": [{"type": "para", "indent": 8, "text": ["Path to the image file or sequence that contains deep data.\n        (The provided ", {"type": "q", "text": ["reload"]}, " button on the side flushes all texture caches.)"], "extent": [803, 951]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Depth Channel"], "extent": [951, 970], "body": [{"type": "para", "indent": 8, "text": ["Name of the channel to treat as depth data.\n        Most frequently it\u2019s ", {"type": "var", "text": ["Pz"]}, " or ", {"type": "var", "text": ["Zback"]}, "."], "extent": [970, 1081]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Proxy Scale"], "extent": [1081, 1098], "body": [{"type": "para", "indent": 8, "text": ["Resolution reduction factor. A value of 1 loads all pixels, a value of 8\n        gives 1/8th resolution (both horizontally and vertically)."], "extent": [1098, 1247]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["First Sample Only"], "extent": [1247, 1270], "body": [{"type": "para", "indent": 8, "text": ["Load only the first depth sample for each pixel.\n        Useful for reducing the data set size for the output point cloud\n        while still getting an approximate depth visualisation."], "extent": [1270, 1469]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Camera Info From"], "extent": [1469, 1491], "body": [{"type": "para", "indent": 8, "text": ["Where to get camera transformation and projection information from."], "extent": [1491, 1576]}, {"type": "dt_group", "body": [{"type": "dt", "indent": 8, "text": ["Deep File Metadata"], "extent": [1576, 1604], "body": [{"type": "para", "indent": 12, "text": ["Use information as metadata embedded in the deep image file(s)."], "extent": [1604, 1693]}, {"type": "note_group", "body": [{"type": "note", "indent": 12, "role": "item", "extent": [1693, 1711], "body": [{"type": "para", "indent": 16, "text": ["This works with mantra, but might not work with other renderers' outputs."], "extent": [1711, 1818]}, {"type": "para", "indent": 16, "text": ["Also, this might not give perfect lineup with motion blurred images,\n                since no motion blur information is stored for the camera transformation\n                metadata. The Camera OBJ Node option might give ", {"type": "q", "text": ["better"]}, " results\n                in that case."], "extent": [1818, 2112]}], "container": true}], "container": true, "role": "item_group"}], "container": true}, {"type": "dt", "indent": 8, "text": ["Camera OBJ Node"], "extent": [2112, 2137], "body": [{"type": "para", "indent": 12, "text": ["Use a camera object node in the scene."], "extent": [2137, 2201]}, {"type": "note_group", "body": [{"type": "note", "indent": 12, "role": "item", "extent": [2201, 2219], "body": [{"type": "para", "indent": 16, "text": ["Make sure this is the same (or matching) camera to the one\n                the deep image(s) were rendered with."], "extent": [2219, 2357]}], "container": true}], "container": true, "role": "item_group"}], "container": true}], "container": true}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Output Attributes"], "extent": [2357, 2381], "body": [{"type": "dt_group", "body": [{"type": "dt", "indent": 8, "text": ["Channels"], "extent": [2381, 2399], "body": [{"type": "para", "indent": 12, "text": ["The deep image channels that should be retrieved as point attributes."], "extent": [2399, 2494]}, {"type": "note_group", "body": [{"type": "note", "indent": 12, "role": "item", "extent": [2494, 2512], "body": [{"type": "para", "indent": 16, "text": ["Currently only float, vector and vector4 types are supported."], "extent": [2512, 2591]}], "container": true}], "container": true, "role": "item_group"}], "container": true}, {"type": "dt", "indent": 8, "text": ["Camera UV"], "extent": [2591, 2610], "body": [{"type": "para", "indent": 12, "text": ["A camera projection (or, screen space) UV attribute."], "extent": [2610, 2688]}, {"type": "tip_group", "body": [{"type": "tip", "indent": 12, "role": "item", "extent": [2688, 2705], "body": [{"type": "para", "indent": 16, "text": ["This can be used in a subsequent ", {"scheme": "Node", "value": "/nodes/sop/attribfrommap", "type": "link", "text": ["Attribute from Map SOP"], "fullpath": "/nodes/sop/attribfrommap.html"}, "\n                to ", {"type": "q", "text": ["colourise"]}, " deep points with a (non-deep) beauty render."], "extent": [2705, 2879]}], "container": true}], "container": true, "role": "item_group"}], "container": true}, {"type": "dt", "indent": 8, "text": ["Pixel Coordinates"], "extent": [2879, 2906], "body": [{"type": "para", "indent": 12, "text": ["Actual pixel X/Y coordinates for each sample."], "extent": [2906, 2965]}], "container": true}, {"type": "dt", "indent": 8, "text": ["Pixel Index"], "extent": [2965, 2986], "body": [{"type": "para", "indent": 12, "text": ["An unique pixel index for each sample point."], "extent": [2986, 3056]}, {"type": "tip_group", "body": [{"type": "tip", "indent": 12, "role": "item", "extent": [3056, 3073], "body": [{"type": "para", "indent": 16, "text": ["This can be used in conjunction with an ", {"scheme": "Node", "value": "/nodes/sop/attribpromote", "type": "link", "text": ["Attribute Promote SOP"], "fullpath": "/nodes/sop/attribpromote.html"}, "\n                to compute (say) an average of all samples. (Set both promotion classes to ", {"type": "q", "text": ["point"]}, ", and\n                use ", {"type": "code", "text": ["pxindex"]}, " as Piece Attribute)."], "extent": [3073, 3333]}], "container": true}], "container": true, "role": "item_group"}], "container": true}], "container": true}], "container": true, "role": "item"}], "container": true, "role": "item_group"}], "text": "Parameters"}, {"level": 1, "id": "related", "container": true, "type": "related_section", "indent": 0, "role": "section", "extent": [3333, 3342], "body": [{"type": "bullet_group", "body": [{"blevel": 6, "type": "bullet", "indent": 4, "text": ["\u2026"], "extent": [3342, 3357]}], "container": true}], "text": "Related"}, {"level": 1, "id": "todo", "container": true, "type": "todo_section", "indent": 0, "text": ["To Do"], "role": "section", "extent": [3357, 3369], "body": [{"type": "bullet_group", "body": [{"blevel": 6, "type": "bullet", "indent": 4, "text": ["Should support overscan properly? (now it doesn\u2019t load overscan areas)"], "extent": [3369, 3446]}, {"blevel": 6, "type": "bullet", "indent": 4, "text": ["Have ", {"type": "q", "text": ["Add Cache SOP"]}, " button"], "extent": [3446, 3480]}, {"blevel": 6, "type": "bullet", "indent": 4, "text": ["Add guide geometry (showing near clip plane maybe? using the camera/projection matrices)"], "extent": [3480, 3575]}, {"blevel": 6, "type": "bullet", "indent": 4, "text": ["Maybe support non-perspective (orthographic) cameras? (Probably low prio)"], "extent": [3575, 3655]}, {"blevel": 6, "type": "bullet", "indent": 4, "text": ["What about motion blur?"], "extent": [3655, 3685]}, {"blevel": 6, "type": "bullet", "indent": 4, "text": ["mantra: regular z buffer of density-like volumes look funny, double check"], "extent": [3685, 3767]}], "container": true}]}, {"level": 1, "id": "relnotes", "container": true, "type": "relnotes_section", "indent": 0, "text": ["Release Notes"], "role": "section", "extent": [3767, 3791], "body": [{"type": "para", "indent": 0, "text": [{"type": "em", "text": ["interface version 1"]}, " \u2014"], "extent": [3791, 3819]}, {"type": "dt_group", "body": [{"type": "dt", "indent": 0, "text": ["2021-10-20"], "extent": [3819, 3831], "body": [{"type": "bullet_group", "body": [{"blevel": 6, "type": "bullet", "indent": 4, "text": ["Added ", {"type": "q", "text": ["Channels"]}, " output attribute field, now can read all"], "extent": [3831, 3895]}, {"blevel": 6, "type": "bullet", "indent": 4, "text": ["Removed previous channel-specific fields (e.g. Of)"], "extent": [3895, 3952]}, {"blevel": 6, "type": "bullet", "indent": 4, "text": ["Not backwards compatible with previous version"], "extent": [3952, 4006]}], "container": true}], "container": true}, {"type": "dt", "indent": 0, "text": ["2021-10-11"], "extent": [4006, 4018], "body": [{"type": "bullet_group", "body": [{"blevel": 6, "type": "bullet", "indent": 4, "text": ["Added option to get camera info from actual camera OBJ node (", {"scheme": null, "value": "https://github.com/qLab/qLib/issues/1290", "type": "link", "text": ["#1290"], "exists": true}, ")"], "extent": [4018, 4136]}], "container": true}], "container": true}, {"type": "dt", "indent": 0, "text": ["2020-08-23"], "extent": [4136, 4148], "body": [{"type": "bullet_group", "body": [{"blevel": 6, "type": "bullet", "indent": 4, "text": ["Now supports regular Z channels of non-deep images"], "extent": [4148, 4206]}], "container": true}], "container": true}, {"type": "dt", "indent": 0, "text": ["2020-08-22"], "extent": [4206, 4218], "body": [{"type": "bullet_group", "body": [{"blevel": 6, "type": "bullet", "indent": 4, "text": ["Updated docs (warning about texture memory caches)."], "extent": [4218, 4277]}], "container": true}], "container": true}, {"type": "dt", "indent": 0, "text": ["2020-08-21"], "extent": [4277, 4289], "body": [{"type": "bullet_group", "body": [{"blevel": 6, "type": "bullet", "indent": 4, "text": ["First version."], "extent": [4289, 4311]}], "container": true}], "container": true}], "container": true}]}], "title": ["Deep to Points qL"], "summary": ["Loads a deep raster image as a point cloud."]}