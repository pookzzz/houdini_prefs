{"type": "root", "attrs": {"type": "node", "context": "top", "internal": "preprocessoidn", "icon": "MISC/generic", "since": "20.5", "index": "no", "version": null, "namespace": null}, "body": [{"level": 0, "type": "title", "indent": 0, "text": ["Preprocess OIDN"], "extent": [0, 20]}, {"type": "summary", "indent": 0, "text": ["Processes training and validation datasets for OIDN model training."], "extent": [118, 193]}, {"level": 2, "id": null, "container": true, "type": "h", "indent": 0, "text": ["Overview"], "extent": [193, 208], "body": [{"type": "para", "indent": 0, "text": ["This node is a wrapper around the OIDN preprocessing script used to preprocess \ntraining and validation datasets compliant with the \n", {"scheme": null, "value": "https://github.com/OpenImageDenoise/oidn?tab=readme-ov-file#datasets", "type": "link", "text": ["OIDN dataset naming scheme"], "exists": true}, "."], "extent": [208, 442]}, {"level": 3, "id": null, "container": true, "type": "h", "indent": 0, "text": ["Installation:"], "extent": [2383, 2403], "body": [{"type": "para", "indent": 4, "text": ["The OIDN scripts require an additional installation of ", {"type": "code", "text": ["torch"]}, " (PyTorch)\n    to ", {"type": "code", "text": ["hython"]}, ". "], "extent": [2435, 2535]}, {"type": "para", "indent": 4, "text": ["Firstly, we intitialize the ", {"type": "code", "text": ["hython"]}, " environment by navigating\n    to the Houdini installation directory."], "extent": [2535, 2646]}, {"type": "platform_group", "body": [{"ext": null, "type": "platform", "indent": 4, "text": ["Linux"], "role": "item", "extent": [2646, 2666]}], "container": true, "role": "item_group"}, {"lang": null, "type": "pre", "indent": 4, "text": ["\n        cd /opt/hfsx.x.x\n    "], "extent": [2666, 2707]}, {"type": "platform_group", "body": [{"ext": null, "type": "platform", "indent": 4, "text": ["Mac"], "role": "item", "extent": [2707, 2726]}], "container": true, "role": "item_group"}, {"lang": null, "type": "pre", "indent": 4, "text": ["\n        cd /Applications/Houdini/Houdinix.x.x/Frameworks/Houdini.framework/Resources\n    "], "extent": [2726, 2827]}, {"type": "platform_group", "body": [{"ext": null, "type": "platform", "indent": 4, "text": ["Windows"], "role": "item", "extent": [2827, 2850]}], "container": true, "role": "item_group"}, {"lang": null, "type": "pre", "indent": 4, "text": ["\n        cd \"C:\\\\Program Files\\\\Side Effects Software\\\\Houdini x.x.x\"\n    "], "extent": [2850, 2935]}, {"type": "para", "indent": 4, "text": ["Then we source the ", {"type": "code", "text": ["houdini_setup"]}, " script, followed by an installation of ", {"type": "code", "text": ["torch"]}, " to ", {"type": "code", "text": ["hython"]}, "."], "extent": [2935, 3036]}, {"lang": null, "type": "pre", "indent": 4, "text": ["\n        source houdini_setup\n        hython -m pip install torch\n    "], "extent": [3036, 3116]}], "attrs": {"id": "torchinstallation"}}]}, {"level": 1, "id": "parameters", "container": true, "type": "parameters_section", "indent": 0, "role": "section", "extent": [484, 496], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 0, "text": ["Input Features"], "extent": [27, 43], "body": [{"type": "para", "indent": 4, "text": ["The set of input features of the dataset to preprocess for training. The\n    following image features are supported:"], "extent": [67, 189]}, {"type": "dt_group", "body": [{"type": "dt", "indent": 4, "text": [{"type": "code", "text": ["hdr"]}], "extent": [189, 200], "body": [{"type": "para", "indent": 8, "text": ["color (high dynamic range) with file extension ", {"type": "code", "text": [".hdr.exr"]}], "extent": [200, 267]}], "container": true}, {"type": "dt", "indent": 4, "text": [{"type": "code", "text": ["ldr"]}], "extent": [267, 278], "body": [{"type": "para", "indent": 8, "text": ["color (low dynamic range) with file extension ", {"type": "code", "text": [".ldr.exr"]}], "extent": [278, 344]}], "container": true}, {"type": "dt", "indent": 4, "text": [{"type": "code", "text": ["sh1"]}], "extent": [344, 355], "body": [{"type": "para", "indent": 8, "text": ["color (normalized L1 spherical harmonics) with file extensions\n        ", {"type": "code", "text": [".sh1x.exr"]}, ", ", {"type": "code", "text": [".sh1y.exr"]}, ", and ", {"type": "code", "text": [".sh1z.exr"]}], "extent": [355, 477]}], "container": true}, {"type": "dt", "indent": 4, "text": [{"type": "code", "text": ["alb"]}], "extent": [477, 488], "body": [{"type": "para", "indent": 8, "text": ["albedo with file extension ", {"type": "code", "text": [".alb.exr"]}], "extent": [488, 535]}], "container": true}, {"type": "dt", "indent": 4, "text": [{"type": "code", "text": ["nrm"]}], "extent": [535, 546], "body": [{"type": "para", "indent": 8, "text": ["shading normal with file extension ", {"type": "code", "text": [".nrm.exr"]}], "extent": [546, 601]}], "container": true}], "container": true}, {"type": "para", "indent": 4, "text": ["All input features are assumed to be noisy, including the auxilliary\n    features (e.g. albedo, normal). The auxiliary feature images are optional\n    inputs which usually improve denoising quality and preserve more details."], "extent": [601, 831]}], "container": true, "attrs": {"id": "inputfeatures"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Clean auxilliary features"], "extent": [831, 858], "body": [{"type": "para", "indent": 4, "text": ["This parameter should be enabled when the auxiliary images are noise-free,\n    in which case the reference auxiliary features are used in training instead\n    of the various noisy auxiliary images."], "extent": [885, 1088]}], "container": true, "attrs": {"id": "cleanauxfeatures"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Filter"], "extent": [1088, 1096], "body": [{"type": "para", "indent": 4, "text": ["The filter to train. The filters are:"], "extent": [1113, 1156]}, {"type": "dt_group", "body": [{"type": "dt", "indent": 4, "text": [{"type": "code", "text": ["RT"]}], "extent": [1156, 1166], "body": [{"type": "para", "indent": 8, "text": ["Generic ray tracing denoising filter suitable for denoising images rendered\n        with Monte Carlo ray tracing methods like unidirectional and bidirectional\n        path tracing."], "extent": [1166, 1356]}], "container": true}, {"type": "dt", "indent": 4, "text": [{"type": "code", "text": ["RTLightmap"]}], "extent": [1356, 1374], "body": [{"type": "para", "indent": 8, "text": ["Variant of RT filter optimized for denoising HDR and normalized\n        directional lightmaps and does not support LDR images."], "extent": [1374, 1510]}], "container": true}], "container": true}, {"type": "para", "indent": 4, "text": ["The choice of filter determines the HDR/LDR transfer function to be used"], "extent": [1510, 1588]}], "container": true, "attrs": {"id": "filter"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Output Directory"], "extent": [605, 623], "body": [{"type": "para", "indent": 4, "text": ["The directory to output preprocessed results."], "extent": [649, 700]}], "container": true, "attrs": {"id": "outputdirectory"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Training Dataset"], "extent": [1588, 1606], "body": [{"type": "para", "indent": 4, "text": ["The name of the training dataset folder."], "extent": [1632, 1678]}], "container": true, "attrs": {"id": "trainingdataset"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Validation Dataset"], "extent": [1678, 1698], "body": [{"type": "para", "indent": 4, "text": ["The name of the validation dataset folder."], "extent": [1726, 1774]}], "container": true, "attrs": {"id": "validationdataset"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Data Directory"], "extent": [781, 797], "body": [{"type": "para", "indent": 4, "text": ["The directory of the training and validation data."], "extent": [821, 877]}], "container": true, "attrs": {"id": "datadirectory"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Device"], "extent": [1774, 1782], "body": [{"type": "para", "indent": 4, "text": ["The device (e.g. CPU, GPU) to use for training computations. The options are:\n    ", {"type": "code", "text": ["cpu"]}, ", ", {"type": "code", "text": ["cuda"]}, ", and ", {"type": "code", "text": ["mps"]}, "."], "extent": [1799, 1912]}], "container": true, "attrs": {"id": "device"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Device ID"], "extent": [1912, 1923], "body": [{"type": "para", "indent": 4, "text": ["The specified device to use if there are multiple devices of the same kind\n    available (e.g. multiple GPUs)."], "extent": [1942, 2058]}], "container": true, "attrs": {"id": "deviceid"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Device Count"], "extent": [2058, 2072], "body": [{"type": "para", "indent": 4, "text": ["The number of devices to use for data-parallel execution for faster performance."], "extent": [2094, 2180]}], "container": true, "attrs": {"id": "devicecount"}, "role": "item"}], "container": true, "role": "item_group"}, {"level": 2, "id": null, "container": true, "type": "h", "indent": 0, "text": ["Advanced"], "extent": [975, 990], "body": [{"type": "para", "indent": 0, "text": ["These are advanced parameters that provide finer control over the behavior of the\npreprocessing."], "extent": [990, 1088]}, {"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 0, "text": ["Transfer Function"], "extent": [2180, 2199], "body": [{"type": "para", "indent": 4, "text": ["The HDR/LDR transfer function to be used."], "extent": [2226, 2273]}], "container": true, "attrs": {"id": "transferfunction"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Deterministic"], "extent": [2273, 2288], "body": [{"type": "para", "indent": 4, "text": ["Make computations deterministic, resulting in slower performance."], "extent": [2312, 2383]}], "container": true, "attrs": {"id": "deterministic"}, "role": "item"}], "container": true, "role": "item_group"}]}], "text": "Parameters"}, {"level": 1, "id": "related", "container": true, "type": "related_section", "indent": 0, "role": "section", "extent": [1167, 1176], "body": [{"type": "bullet_group", "body": [{"blevel": 2, "type": "bullet", "indent": 0, "text": [{"scheme": "Node", "value": "/nodes/top/trainoidn", "type": "link", "text": "", "fullpath": "/nodes/top/trainoidn.html"}], "extent": [1176, 1200]}], "container": true}], "text": "Related"}], "title": ["Preprocess OIDN"], "summary": ["Processes training and validation datasets for OIDN model training."], "included": ["/nodes/top/_oidn_common"]}