{"type": "root", "attrs": {"type": "include"}, "body": [{"type": "dt_group", "body": [{"type": "dt", "indent": 0, "text": ["Working Directory"], "extent": [16, 35], "body": [{"type": "para", "indent": 4, "text": ["Specifies the relative directory where the work generates intermediate files and output. The intermediate files are placed in a subdirectory. For the Local Scheduler or HQueue, typically ", {"type": "code", "text": ["$HIP"]}, " is used. For other schedulers, this should be a relative directory to ", {"type": "code", "text": ["Local Shared Root Path"]}, " and ", {"type": "code", "text": ["Remote Shared Root Path"]}, "; this path is then appended to these root paths."], "extent": [60, 433]}], "container": true, "attrs": {"id": "pdg_workingdir"}}, {"type": "dt", "indent": 0, "text": ["Path Mapping"], "extent": [433, 447], "body": [{"type": "dt_group", "body": [{"type": "dt", "indent": 4, "text": ["Global"], "extent": [469, 481], "body": [{"type": "para", "indent": 8, "text": ["If the ", {"scheme": null, "value": "/ref/panes/pdgpathmap", "type": "link", "text": ["PDG Path Map"], "fullpath": "/ref/panes/pdgpathmap.html"}, " exists, then it is applied to file paths."], "extent": [481, 576]}], "container": true}, {"type": "dt", "indent": 4, "text": ["None"], "extent": [576, 586], "body": [{"type": "para", "indent": 8, "text": ["Delocalizes paths using the ", {"type": "code", "text": ["PDG_DIR"]}, " token."], "extent": [586, 640]}], "container": true}], "container": true}], "container": true, "attrs": {"id": "pdg_mapmode"}}, {"type": "dt", "indent": 0, "text": ["Path Map Zone"], "extent": [640, 655], "body": [{"type": "para", "indent": 4, "text": ["When on, specifies a custom mapping zone to apply to all jobs executed by this scheduler. Otherwise, the local platforms are ", {"type": "code", "text": ["LINUX"]}, ", ", {"type": "code", "text": ["MAC"]}, " or ", {"type": "code", "text": ["WIN"]}, "."], "extent": [677, 832]}], "container": true, "attrs": {"id": "pdg_mapzone"}}, {"type": "dt", "indent": 0, "text": ["Validate Outputs When Recooking"], "extent": [832, 865], "body": [{"type": "para", "indent": 4, "text": ["When on, PDG validates the output files of the scheduler\u2019s cooked work items when the graph is recooked to see if the files still exist on disk. Work items that are missing output files are then automatically dirtied and cooked again. If any work items are dirtied by parameter changes, then their cache files are also automatically invalidated. ", {"type": "ui", "text": ["Validate Outputs When Recooking"]}, " is ", {"type": "em", "text": ["on"]}, " by default."], "extent": [895, 1302]}], "container": true, "attrs": {"id": "pdg_validateoutputs"}}, {"type": "dt", "indent": 0, "text": ["Check Expected Outputs on Disk"], "extent": [1302, 1334], "body": [{"type": "para", "indent": 4, "text": ["When on, PDG looks for any unexpected outputs (for example, like outputs that can result from custom output handling internal logic) that were not explicitly reported when the scheduler\u2019s work items finished cooking. This check occurs immediately after the scheduler marks work items as cooked, and expected outputs that were reported normally are not checked. If PDG finds any files that are different from the expected outputs, then they are automatically added as real output files."], "extent": [1369, 1860]}], "container": true, "attrs": {"id": "pdg_checkexpectedoutputs"}}, {"type": "dt", "indent": 0, "text": ["Limit Jobs"], "extent": [1860, 1872], "body": [{"type": "para", "indent": 4, "text": ["When enabled, sets the maximum number of jobs that can be submitted by the scheduler at the same time."], "extent": [1895, 2003]}, {"type": "para", "indent": 4, "text": ["For farm schedulers like Tractor or HQueue, this parameter can be used to limit the total number of jobs submitted to the render farm itself. Setting this parameter can help limit the load on the render farm, especially when the PDG graph has a large number of small tasks."], "extent": [2003, 2282]}], "container": true, "attrs": {"id": "pdg_maxtasks"}}, {"type": "dt", "indent": 0, "text": ["Tick Period"], "extent": [2282, 2295], "body": [{"type": "para", "indent": 4, "text": ["Sets the minimum time (in seconds) between calls to the ", {"type": "code", "text": ["onTick"]}, " callback."], "extent": [2320, 2400]}], "container": true, "attrs": {"id": "pdg_tickperiod"}}, {"type": "dt", "indent": 0, "text": ["Max Items Per Tick"], "extent": [2400, 2420], "body": [{"type": "para", "indent": 4, "text": ["Sets the maximum number of ready item ", {"type": "code", "text": ["onSchedule"]}, " callbacks between ticks."], "extent": [2443, 2524]}], "container": true, "attrs": {"id": "pdg_maxitems"}}, {"type": "dt", "indent": 0, "text": ["Local Shared Root Path"], "extent": [2524, 2548], "body": [{"type": "para", "indent": 4, "text": ["Specifies the absolute path to the mounted directory on the local machine at which the working directory is rooted."], "extent": [2574, 2695]}], "container": true, "attrs": {"id": "localsharedroot"}}, {"type": "dt", "indent": 0, "text": ["Remote Shared Root Path"], "extent": [2695, 2720], "body": [{"type": "para", "indent": 4, "text": ["When on, specifies the path to the mounted directory on client machines at which the working directory is rooted. This can include variables that the farm is set to resolve to platform-specific paths."], "extent": [2747, 2953]}], "container": true, "attrs": {"id": "remotesharedroot"}}, {"type": "dt", "indent": 0, "text": ["Override Port Range"], "extent": [2953, 2974], "body": [{"type": "para", "indent": 4, "text": ["When on, overrides the callback server\u2019s default port range."], "extent": [3002, 3068]}], "container": true, "attrs": {"id": "overrideportrange"}}, {"type": "dt", "indent": 0, "text": ["Callback Port Range"], "extent": [3068, 3089], "body": [{"type": "para", "indent": 4, "text": ["Specifies the callback server\u2019s port range values to use when overriding the default values."], "extent": [3117, 3215]}], "container": true, "attrs": {"id": "callbackportrange"}}], "container": true}, {"level": 2, "id": "network", "container": true, "type": "h", "indent": 0, "text": ["Network Requirements"], "extent": [3215, 3252], "body": [{"type": "para", "indent": 0, "text": ["As part of the cook, a message queue (MQ) job is submitted. This job is used to communicate information from executing jobs back to the submitting machine. For this reason, your farm machines must be able to resolve the hostnames of other farm machines."], "extent": [3252, 3508]}, {"type": "tip_group", "body": [{"type": "tip", "indent": 0, "role": "item", "extent": [3508, 3513], "body": [{"type": "para", "indent": 4, "text": ["This is as simple as editing the ", {"type": "code", "text": ["/etc/hosts"]}, " (Linux / macOS) or ", {"type": "code", "text": ["C:\\Windows\\System32\\Drivers\\etc\\hosts"]}, " (Windows)."], "extent": [3513, 3634]}], "container": true}], "container": true, "role": "item_group"}, {"type": "para", "indent": 0, "text": ["In addition, farm machines must ", {"type": "em", "text": ["not"]}, " have firewalls between them, or you need to use the ", {"type": "ui", "text": ["Task Callback Port"]}, " parameter to specify the open port to use."], "extent": [3634, 3791]}, {"type": "para", "indent": 0, "text": ["When the cook starts, the submitting machine connects to the farm machine that is running the MQ job. So farm machines also must ", {"type": "em", "text": ["not"]}, " have firewalls between them and the submitting machine, or you need to use the ", {"type": "ui", "text": ["Relay Port"]}, " parameter to specify the open port to use."], "extent": [3791, 4064]}, {"type": "dt_group", "body": [{"type": "dt", "indent": 0, "text": ["Enable Server"], "extent": [4064, 4079], "body": [{"type": "para", "indent": 4, "text": ["When on, turns on the data layer server for the TOP job that will cook on the farm. This allows PilotPDG or other WebSocket clients to connect to the cooking job remotely to view the state of PDG."], "extent": [4111, 4313]}], "container": true, "attrs": {"id": "enabledatalayerserver"}}, {"type": "dt", "indent": 0, "text": ["Server Port"], "extent": [4313, 4326], "body": [{"type": "para", "indent": 4, "text": ["Determines which server port to use for the data layer server."], "extent": [4353, 4421]}, {"type": "para", "indent": 4, "text": ["This parameter is only available when ", {"type": "ui", "text": ["Enable Server"]}, " is ", {"type": "em", "text": ["on"]}, "."], "extent": [4421, 4491]}, {"type": "dt_group", "body": [{"type": "dt", "indent": 4, "text": ["Automatic"], "extent": [4491, 4506], "body": [{"type": "para", "indent": 8, "text": ["A free TCP port to use for the data layer server chosen by the node."], "extent": [4506, 4584]}], "container": true}, {"type": "dt", "indent": 4, "text": ["Custom"], "extent": [4584, 4596], "body": [{"type": "para", "indent": 8, "text": ["A custom TCP port to use for the data layer server specified by the user."], "extent": [4596, 4679]}, {"type": "para", "indent": 8, "text": ["This is useful when there is a firewall between the farm machine and the monitoring machine."], "extent": [4679, 4781]}], "container": true}], "container": true}], "container": true, "attrs": {"id": "usedatalayerport"}}, {"type": "dt", "indent": 0, "text": ["Auto Connect"], "extent": [4781, 4795], "body": [{"type": "para", "indent": 4, "text": ["When on, the scheduler will try to send a command to create a remote visualizer when the job starts. If successful, then a remote graph is created and is automatically connected to the server executing the job. The client submitting the job ", {"type": "em", "text": ["must"]}, " be visible to the server running the job or the connection will fail."], "extent": [4823, 5146]}, {"type": "para", "indent": 4, "text": ["This parameter is only available when ", {"type": "ui", "text": ["Enable Server"]}, " is ", {"type": "em", "text": ["on"]}, "."], "extent": [5146, 5216]}], "container": true, "attrs": {"id": "createremotegraph"}}, {"type": "dt", "indent": 0, "text": ["When Finished"], "extent": [5216, 5231], "body": [{"type": "para", "indent": 4, "text": ["Determines what to do when the TOP Cook finishes. This allows the TOP Cook job to continue running after the graph cook completes so that it can be inspected by a wrangler using a ", {"scheme": null, "value": "/tops/datalayer", "type": "link", "text": ["Data Layer"], "fullpath": "/tops/datalayer.html"}, " viewer. For example, with ", {"type": "ui", "text": ["When Finished"]}, " you can retry a failed work item without restarting its whole job."], "extent": [5263, 5592]}, {"type": "dt_group", "body": [{"type": "dt", "indent": 4, "text": ["Terminate"], "extent": [5592, 5607], "body": [{"type": "para", "indent": 8, "text": ["Exit the job as normal."], "extent": [5607, 5644]}], "container": true}, {"type": "dt", "indent": 4, "text": ["Keep Open If Error"], "extent": [5644, 5668], "body": [{"type": "para", "indent": 8, "text": ["Keep the job running only if there is an error detected. You will need to kill the job manually."], "extent": [5668, 5774]}], "container": true}, {"type": "dt", "indent": 4, "text": ["Keep Open"], "extent": [5774, 5789], "body": [{"type": "para", "indent": 8, "text": ["Keep the job running. You will need to kill the job manually."], "extent": [5789, 5860]}], "container": true}], "container": true}], "container": true, "attrs": {"id": "submitjobwhenfinished"}}, {"type": "dt", "indent": 0, "text": ["Block on Failed Work Items"], "extent": [5860, 5888], "body": [{"type": "para", "indent": 4, "text": ["When on, if there are any failed work items on the scheduler, then the cook is blocked from completing and the PDG graph cook is prevented from ending. This allows you to manually retry your failed work items. You can ", {"type": "em", "text": ["cancel"]}, " the scheduler\u2019s cook when it is blocked by failed work items by pressing the ", {"keys": ["ESC"], "type": "keys", "text": null}, " key, clicking the ", {"type": "ui", "text": ["Cancels the current cook"]}, " button in the ", {"scheme": null, "value": "/tops/ui#tasks_bar", "type": "link", "text": ["TOP tasks bar"], "fullpath": "/tops/ui.html#tasks_bar", "fragment": "#tasks_bar"}, ", or by using the cancel API method."], "extent": [5918, 6367]}], "container": true, "attrs": {"id": "pdg_waitforfailures"}}, {"type": "dt", "indent": 0, "text": ["Auto retry downstream tasks"], "extent": [6367, 6396], "body": [{"type": "para", "indent": 4, "text": ["When on, if a parent tasks is retried manually, then its child tasks will also be retried. This parameter is only available when ", {"type": "ui", "text": ["Block on Failed Work Items"]}, " is turned ", {"type": "em", "text": ["on"]}, "."], "extent": [6426, 6607]}], "container": true, "attrs": {"id": "autoretryfailedtask"}}, {"type": "dt", "indent": 0, "text": ["Hython"], "extent": [6607, 6615], "body": [{"type": "para", "indent": 4, "text": ["Determines which Houdini Python interpreter (hython) is used for your Houdini jobs. You can also specify this hython in a command using the ", {"type": "code", "text": ["PDG_HYTHON"]}, " token."], "extent": [6639, 6804]}, {"type": "dt_group", "body": [{"type": "dt", "indent": 4, "text": ["Default"], "extent": [6804, 6817], "body": [{"type": "para", "indent": 8, "text": ["Use the default hython interpreter that is installed with Houdini."], "extent": [6817, 6893]}], "container": true}, {"type": "dt", "indent": 4, "text": ["Custom"], "extent": [6893, 6905], "body": [{"type": "para", "indent": 8, "text": ["Use the executable path specified by the ", {"type": "ui", "text": ["Hython Executable"]}, " parameter."], "extent": [6905, 6988]}], "container": true}], "container": true}], "container": true, "attrs": {"id": "pdg_hythonbin"}}, {"type": "dt", "indent": 0, "text": ["Hython Executable"], "extent": [6988, 7007], "body": [{"type": "para", "indent": 4, "text": ["This parameter is only available when ", {"type": "ui", "text": ["Hython"]}, " is set to ", {"type": "ui", "text": ["Custom"]}, "."], "extent": [7046, 7122]}, {"type": "para", "indent": 4, "text": ["The full path to the hython executable to use for your Houdini jobs."], "extent": [7122, 7196]}], "container": true, "attrs": {"id": "pdg_hythonbincustomuniversal"}}, {"type": "dt", "indent": 0, "text": ["Load Item Data From"], "extent": [7196, 7217], "body": [{"type": "para", "indent": 4, "text": ["Determines how jobs processed by this scheduler should load work item attributes and data. "], "extent": [7250, 7347]}, {"type": "dt_group", "body": [{"type": "dt", "indent": 4, "text": ["Temporary JSON File"], "extent": [7347, 7372], "body": [{"type": "para", "indent": 8, "text": ["The scheduler writes out a ", {"type": "code", "text": [".json"]}, " file for each work item to the PDG temporary file directory. This option is selected by default."], "extent": [7372, 7513]}], "container": true}, {"type": "dt", "indent": 4, "text": ["RPC Message"], "extent": [7513, 7530], "body": [{"type": "para", "indent": 8, "text": ["The scheduler\u2019s running work items request attributes and data over RPC. If the scheduler is a farm scheduler, then the job scripts running on the farm will also request item data from the submitter when creating their out-of-process work item objects. "], "extent": [7530, 7793]}, {"type": "para", "indent": 8, "text": ["This parameter option removes the need to write data files to disk and is useful when your local and remote machines ", {"type": "em", "text": ["do not"]}, " share a file system."], "extent": [7793, 7949]}], "container": true}], "container": true}], "container": true, "attrs": {"id": "pdg_workitemdatasource"}}, {"type": "dt", "indent": 0, "text": ["Delete Temp Dir"], "extent": [7949, 7966], "body": [{"type": "para", "indent": 4, "text": ["Determines when PDG should automatically delete the temporary file directory associated with the scheduler."], "extent": [7994, 8107]}, {"type": "dt_group", "body": [{"type": "dt", "indent": 4, "text": ["Never"], "extent": [8107, 8118], "body": [{"type": "para", "indent": 8, "text": ["PDG never automatically deletes the temp file directory."], "extent": [8118, 8184]}], "container": true}, {"type": "dt", "indent": 4, "text": ["When Scheduler is Deleted"], "extent": [8184, 8215], "body": [{"type": "para", "indent": 8, "text": ["PDG automatically deletes the temp file directory when the scheduler is deleted or when Houdini is closed."], "extent": [8215, 8331]}], "container": true}, {"type": "dt", "indent": 4, "text": ["When Cook Completes"], "extent": [8331, 8356], "body": [{"type": "para", "indent": 8, "text": ["PDG automatically deletes the temp file directory each time a cook completes."], "extent": [8356, 8443]}], "container": true}], "container": true}], "container": true, "attrs": {"id": "pdg_deletetempdir"}}, {"type": "dt", "indent": 0, "text": ["Compress Work Item Data"], "extent": [8443, 8468], "body": [{"type": "para", "indent": 4, "text": ["When on, PDG compresses the work item ", {"type": "code", "text": [".json"]}, " files when writing them to disk."], "extent": [8503, 8587]}, {"type": "para", "indent": 4, "text": ["This parameter is only available when ", {"type": "ui", "text": ["Load Item Data From"]}, " is set to ", {"type": "ui", "text": ["Temporary JSON File"]}, "."], "extent": [8587, 8689]}], "container": true, "attrs": {"id": "pdg_compressworkitemdata"}}, {"type": "dt", "indent": 0, "text": ["Ignore RPC Errors"], "extent": [8689, 8708], "body": [{"type": "para", "indent": 4, "text": ["Determines whether RPC errors should cause out of process jobs to fail."], "extent": [8738, 8815]}, {"type": "dt_group", "body": [{"type": "dt", "indent": 4, "text": ["Never"], "extent": [8815, 8826], "body": [{"type": "para", "indent": 8, "text": ["RPC connection errors will cause work items to fail."], "extent": [8826, 8888]}], "container": true}, {"type": "dt", "indent": 4, "text": ["When Cooking Batches"], "extent": [8888, 8914], "body": [{"type": "para", "indent": 8, "text": ["RPC connection errors are ignored for batch work items, which typically make a per-frame RPC back to PDG to report output files and communicate sub item status. This option prevents long-running simulations from being killed on the farm, if the submitter Houdini session crashes or becomes unresponsive."], "extent": [8914, 9227]}], "container": true}, {"type": "dt", "indent": 4, "text": ["Always"], "extent": [9227, 9239], "body": [{"type": "para", "indent": 8, "text": ["RPC connection errors will never cause a work item to fail. Note that if a work item can\u2019t communicate with the scheduler, it will be unable to report output files, attributes or its cook status back to the PDG graph."], "extent": [9239, 9466]}], "container": true}], "container": true}], "container": true, "attrs": {"id": "pdg_rpcignoreerrors"}}, {"type": "dt", "indent": 0, "text": ["Max RPC Errors"], "extent": [9466, 9482], "body": [{"type": "para", "indent": 4, "text": ["The maximum number of RPC failures that can occur before RPC is disabled in an out of process job."], "extent": [9509, 9613]}], "container": true, "attrs": {"id": "pdg_rpcmaxerrors"}}, {"type": "dt", "indent": 0, "text": ["Connection Timeout"], "extent": [9613, 9633], "body": [{"type": "para", "indent": 4, "text": ["The number of seconds to wait when an out of process jobs makes an RPC connection to the main PDG graph, before assuming the connection failed."], "extent": [9658, 9807]}], "container": true, "attrs": {"id": "pdg_rpctimeout"}}, {"type": "dt", "indent": 0, "text": ["Connection Retries"], "extent": [9807, 9827], "body": [{"type": "para", "indent": 4, "text": ["The number of times to retry a failed RPC call made by an out of process job."], "extent": [9852, 9935]}], "container": true, "attrs": {"id": "pdg_rpcretries"}}, {"type": "dt", "indent": 0, "text": ["Retry Backoff"], "extent": [9935, 9950], "body": [{"type": "para", "indent": 4, "text": ["When ", {"type": "ui", "text": ["Connection Retries"]}, " is greater than 0, this parameter determines how much time should be spent between consecutive retries."], "extent": [9975, 10112]}], "container": true, "attrs": {"id": "pdg_rpcbackoff"}}, {"type": "dt", "indent": 0, "text": ["Batch Poll Rate"], "extent": [10112, 10129], "body": [{"type": "para", "indent": 4, "text": ["Determines how quickly an out of process batch work item should poll the main Houdini session for dependency status updates, if the batch is configured to cook when it\u2019s first frame of work is ready. This has no impact on other types of batch work items."], "extent": [10152, 10412]}], "container": true, "attrs": {"id": "pdg_rpcbatch"}}, {"type": "dt", "indent": 0, "text": ["Release Job Slot When Polling"], "extent": [10412, 10443], "body": [{"type": "para", "indent": 4, "text": ["Determines whether or not the scheduler should decrement the number of active workers when a batch is polling for dependency updates."], "extent": [10468, 10606]}], "container": true, "attrs": {"id": "pdg_rpcrelease"}}], "container": true}]}]}